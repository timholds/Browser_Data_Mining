{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_json(\"Chrome_Data/Chrome/BrowserHistory2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a new dataframe and drop unwanted columns \n",
    "dataframe = data.drop(['client_id', 'favicon_url'], 1)\n",
    "\n",
    "#put rows in chronological order\n",
    "df = dataframe.sort_values(['time_usec'], ascending=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url_shortener(df):\n",
    "    if (df.url[0:3] == 'chr'):\n",
    "        return df.url[71:]\n",
    "    else:\n",
    "        return df.url\n",
    "        \n",
    "df['url_short'] = df.apply(url_shortener, axis=1)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_time(df):\n",
    "    df['time_usec'] = df['time_usec']/1000000\n",
    "    return datetime.datetime.fromtimestamp(\n",
    "        int(df['time_usec'])\n",
    "    ).strftime('%Y-%m-%d %H:%M:%S')        \n",
    "    \n",
    "df['dates_and_times'] = df.apply(date_time, axis=1)\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.set_index(['dates_and_times'])\n",
    "df.index.name=None\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_transition</th>\n",
       "      <th>title</th>\n",
       "      <th>url_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-12 10:45:17</th>\n",
       "      <td>AUTO_BOOKMARK</td>\n",
       "      <td>Activity - Op L.E. - Google Docs</td>\n",
       "      <td>https://docs.google.com/document/d/1fzerSwYRhH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-12 10:47:27</th>\n",
       "      <td>LINK</td>\n",
       "      <td></td>\n",
       "      <td>http://www.centroportici.unina.it/centro/Camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-12 10:47:35</th>\n",
       "      <td>LINK</td>\n",
       "      <td></td>\n",
       "      <td>http://cameron.econ.ucdavis.edu/mmabook/mmadif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-12 10:47:47</th>\n",
       "      <td>LINK</td>\n",
       "      <td>Suspended Tab</td>\n",
       "      <td>http://www.autonlab.org/tutorials/gaussian.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-12 10:52:09</th>\n",
       "      <td>LINK</td>\n",
       "      <td>Suspended Tab</td>\n",
       "      <td>https://www.cs.cmu.edu/~mblum/search/AGTML35.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    page_transition                             title  \\\n",
       "2016-11-12 10:45:17   AUTO_BOOKMARK  Activity - Op L.E. - Google Docs   \n",
       "2016-11-12 10:47:27            LINK                                     \n",
       "2016-11-12 10:47:35            LINK                                     \n",
       "2016-11-12 10:47:47            LINK                     Suspended Tab   \n",
       "2016-11-12 10:52:09            LINK                     Suspended Tab   \n",
       "\n",
       "                                                             url_short  \n",
       "2016-11-12 10:45:17  https://docs.google.com/document/d/1fzerSwYRhH...  \n",
       "2016-11-12 10:47:27  http://www.centroportici.unina.it/centro/Camer...  \n",
       "2016-11-12 10:47:35  http://cameron.econ.ucdavis.edu/mmabook/mmadif...  \n",
       "2016-11-12 10:47:47    http://www.autonlab.org/tutorials/gaussian.html  \n",
       "2016-11-12 10:52:09   https://www.cs.cmu.edu/~mblum/search/AGTML35.pdf  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a copy of the dataframe and drop unneccesary columns\n",
    "df1 = pd.DataFrame.copy(df)\n",
    "df1 = df1.drop(['time_usec', 'url'], 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>page_transition</th>\n",
       "      <th>title</th>\n",
       "      <th>url_short</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-12 10:45:17</td>\n",
       "      <td>AUTO_BOOKMARK</td>\n",
       "      <td>Activity - Op L.E. - Google Docs</td>\n",
       "      <td>https://docs.google.com/document/d/1fzerSwYRhH...</td>\n",
       "      <td>docs.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-12 10:47:27</td>\n",
       "      <td>LINK</td>\n",
       "      <td></td>\n",
       "      <td>http://www.centroportici.unina.it/centro/Camer...</td>\n",
       "      <td>www.centroportici.unina.it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-12 10:47:35</td>\n",
       "      <td>LINK</td>\n",
       "      <td></td>\n",
       "      <td>http://cameron.econ.ucdavis.edu/mmabook/mmadif...</td>\n",
       "      <td>cameron.econ.ucdavis.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-12 10:47:47</td>\n",
       "      <td>LINK</td>\n",
       "      <td>Suspended Tab</td>\n",
       "      <td>http://www.autonlab.org/tutorials/gaussian.html</td>\n",
       "      <td>www.autonlab.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-12 10:52:09</td>\n",
       "      <td>LINK</td>\n",
       "      <td>Suspended Tab</td>\n",
       "      <td>https://www.cs.cmu.edu/~mblum/search/AGTML35.pdf</td>\n",
       "      <td>www.cs.cmu.edu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index page_transition                             title  \\\n",
       "0  2016-11-12 10:45:17   AUTO_BOOKMARK  Activity - Op L.E. - Google Docs   \n",
       "1  2016-11-12 10:47:27            LINK                                     \n",
       "2  2016-11-12 10:47:35            LINK                                     \n",
       "3  2016-11-12 10:47:47            LINK                     Suspended Tab   \n",
       "4  2016-11-12 10:52:09            LINK                     Suspended Tab   \n",
       "\n",
       "                                           url_short  \\\n",
       "0  https://docs.google.com/document/d/1fzerSwYRhH...   \n",
       "1  http://www.centroportici.unina.it/centro/Camer...   \n",
       "2  http://cameron.econ.ucdavis.edu/mmabook/mmadif...   \n",
       "3    http://www.autonlab.org/tutorials/gaussian.html   \n",
       "4   https://www.cs.cmu.edu/~mblum/search/AGTML35.pdf   \n",
       "\n",
       "                         page  \n",
       "0             docs.google.com  \n",
       "1  www.centroportici.unina.it  \n",
       "2    cameron.econ.ucdavis.edu  \n",
       "3            www.autonlab.org  \n",
       "4              www.cs.cmu.edu  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main_url_extractor(df):\n",
    "    u = urlparse(df['url_short'])\n",
    "    return u.netloc\n",
    "    \n",
    "df1['page'] = df1.apply(main_url_extractor, axis = 1)\n",
    "df1.reset_index(inplace=True)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    }
   ],
   "source": [
    "sites = df1['page']\n",
    "def unique_urls(df1):\n",
    "    sites_unique = set(sites)\n",
    "    return sites_unique\n",
    "\n",
    "site_list = unique_urls(df1)\n",
    "print(type(site_list))\n",
    "#site_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.indexes.range.RangeIndex'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df1.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values (i.e. inferred_type is 'string', 'unicode' or 'mixed')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7c0ec7d3bdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtime_slicing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#df1['hour'] = df1.apply(time_slicing, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#for i in range(0, 3):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7c0ec7d3bdd2>\u001b[0m in \u001b[0;36mtime_slicing\u001b[0;34m(df1)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtime_slicing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# this ensures that Series.str.<method> is well defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccessor_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_make_str_accessor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1826\u001b[0m                            \u001b[0;34m\"(i.e. inferred_type is 'string', 'unicode' or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m                            \"'mixed')\")\n\u001b[0;32m-> 1828\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m                 message = (\"Can only use .str accessor with Index, not \"\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values (i.e. inferred_type is 'string', 'unicode' or 'mixed')"
     ]
    }
   ],
   "source": [
    "#create a list to track clicks on a given website by hour of day \n",
    "bins = []\n",
    "for i in range(0, 24):\n",
    "    bins.append(i)\n",
    "#create an empty list for clicks, which we will fill later\n",
    "clicks = [0] * 24\n",
    "hour_clicks = pd.Series(clicks, bins)\n",
    "\n",
    "def time_slicing(df1):\n",
    "    a = df1.index[11:13]\n",
    "    return a\n",
    "\n",
    "time_slicing(df1)\n",
    "#df1['hour'] = df1.apply(time_slicing, axis=1)\n",
    "#for i in range(0, 3):\n",
    " #   hour_clicks[i] = hour_clicks[i] + 1\n",
    "\n",
    "#hour_clicks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(df1)):\n",
    "   x = (df1.hour.iloc[i] == '12')\n",
    "x\n",
    "#clicks[12] = len(x)\n",
    "#clicks[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clicks_hour(df):      \n",
    "    s = df['hour'].tolist()\n",
    "    #for v in s:\n",
    "        #print(v)\n",
    "    #   hour_clicks[v] = hour_clicks[v] + 1\n",
    "    #return hour_clicks\n",
    "    return s\n",
    "\n",
    "clicks_hour(df)\n",
    "\n",
    "#for t in df1['hour'].iteritems():    \n",
    "       # print(t)\n",
    "#def click_by_hour():\n",
    "    #Read a line of the dataframe, determine which row to augment \n",
    "    #read the value v for a line under the hour column. take this value vand pass it to a function\n",
    "    #that augments the hour_clicks at row v by one\n",
    "    #for line in df1, check value \n",
    "    #if (df1['hour']\n",
    "    #return #series object with number of clicks for each hour of the day\n",
    "    #get the value of the item at position j in list, with v between 0 and 23\n",
    "    #v = int(list[timestamp])\n",
    "    #use this value to add one to that same hour in hours/clicks\n",
    "    #clicks[v] = clicks[v] + 1\n",
    "    #return clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hour_clicks_plot():\n",
    "    hour_clicks.plot.bar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def click_by_hour(int v):\n",
    "    for timestamp in range(0, len(timestamp_list)):\n",
    "        #get the value of the item at position j in list, with v between 0 and 23\n",
    "        v = int(list[timestamp])\n",
    "        #use this value to add one to that same hour in hours/clicks\n",
    "        clicks[v] = clicks[v] + 1\n",
    "        return clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cameron.econ.ucdavis.edu': 1,\n",
       " 'docs.google.com': 1,\n",
       " 'www.autonlab.org': 1,\n",
       " 'www.centroportici.unina.it': 1,\n",
       " 'www.cs.cmu.edu': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Page']\n",
    "def website_counter(df1):\n",
    "    site_count = {} \n",
    "    for site in sites:\n",
    "    # Special case if we're seeing this word for the first time.\n",
    "        if not site in site_count:\n",
    "            site_count[site] = 1\n",
    "        else:\n",
    "            site_count[site] = site_count[site] + 1\n",
    "    return site_count\n",
    "\n",
    "site_count = website_counter(df1)\n",
    "site_count\n",
    "#print(type(site_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "site_count = pd.Series(site_count)\n",
    "site_count = pd.Series.sort_values(site_count)\n",
    "site_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_sites():\n",
    "    s = site_count[(site_count > 250)]\n",
    "    return s\n",
    "\n",
    "ts = top_sites()\n",
    "print(type(ts))\n",
    "print(ts)\n",
    "#ts.plot.bar(title = 'Top Sites', xticks = )\n",
    "#ax1 = plt.subplot()\n",
    "#ax1.plot(ts)\n",
    "#ax1.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "#fig().autofmt_xdate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def occasional_sites():\n",
    "    #s1 = site_count_series[(site_count_series < 1500)]\n",
    "    s2 = site_count[site_count > 180]\n",
    "    #s3 = pd.Series(set(s1) & set(s2))\n",
    "    return s2.head()\n",
    "\n",
    "occasional_sites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a list to track clicks on a given website by hour of day \n",
    "hours = []\n",
    "for i in range(1, 24):\n",
    "    hours.append(i)\n",
    "#create an empty list for clicks, which we will fill later\n",
    "clicks = [0] * 23\n",
    "hour_clicks = pd.Series(clicks, hours)\n",
    "hour_clicks\n",
    "\"\"\"\n",
    "for i in range(1, 24):\n",
    "    hour_clicks[i] = i + 1\n",
    "    print(hour_clicks[i])\n",
    "    \"\"\"\n",
    "    \n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a df with data from a certain site, webassign in this case\n",
    "webassign_df = df1[df1['page'] == \"www.webassign.net\"]\n",
    "#get only the hour of day from the datetime index\n",
    "a = webassign_df.index.str[11:13]\n",
    "#print(a)\n",
    "#b = df.apply(a, int(a))\n",
    "#timestamp_list = a.tolist()\n",
    "#\\timestamp_list2 = list(map(int, timestamp_list) for x in timestamp_list)\n",
    "#for timestamp in range(0, len(timestamp_list)):\n",
    "    #get the value of the item at a given position in list, with timestamp between 0 and 23\n",
    "    #v = int(timestamp_list[timestamp])\n",
    "#v = int([timestamp_list])\n",
    "print(a)\n",
    "#print(timestamp_list)\n",
    "\n",
    "#for i in range(0, len(a)):\n",
    " #  print(list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def time_slicing():\n",
    "    for timestamp in range(0, len(timestamp_list)):\n",
    "        #get the value of the item at position j in list, with v between 0 and 23\n",
    "        v = int(list[timestamp])\n",
    "        #use this value to add one to that same hour in hours/clicks\n",
    "        clicks[v] = clicks[v] + 1\n",
    "        return clicks\n",
    "\n",
    "time_slicing()\n",
    "        \n",
    "    #make a df with data from a certain site, webassign in this case\n",
    "    #webassign_df = df1[df1['page'] == \"www.webassign.net\"]\n",
    "    #get only the hour of day frmo the datetime index\n",
    "    #webassign_df.index.str[11:]\n",
    "    #Add a click to the hour_clicks series at row i corresponding with hour of day\n",
    "    #for \n",
    "        #hour_clicks[i] = hour_clicks[i] + 1\n",
    "    #return hour_clicks\n",
    "    \n",
    "#time_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill the list with the number of clicks in a given hour\n",
    "#makes a df with data from a certain site, webassign in this case\n",
    "webassign_df = df1[df1['page'] == \"www.webassign.net\"] \n",
    "#parse the date-time index to tally up website visits by hour of day\n",
    "webassign_df[webassign_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#determine what possible values are under the page_transition column\n",
    "def transition_values(df):\n",
    "    print(df['page_transition'].unique())\n",
    "    \n",
    "print(type(transition_values(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count number of sites generated using each page transition using boolean masking\n",
    "def page_transition_counter(df):\n",
    "    links = df[df['page_transition'] == \"LINK\"]\n",
    "    generated = df[df['page_transition'] == \"GENERATED\"]\n",
    "    auto_bookmarks = df[df['page_transition'] == \"AUTO_BOOKMARK\"]\n",
    "    typed = df[df['page_transition'] == \"TYPED\"]\n",
    "    reload = df[df['page_transition'] == \"RELOAD\"]\n",
    "    form_submit = df[df['page_transition'] == \"FORM_SUBMIT\"]\n",
    "    auto_toplevel = df[df['page_transition'] == \"AUTO_TOPLEVEl\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_rows = (len(links) + len(generated) + len(auto_bookmarks) + len(typed) #+ len(reload) +  + len(auto_toplevel))\n",
    "total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(type(df['time_usec']))# = df.index\n",
    "#df[df['time_usec']] #= df.set_index(['time_usec'])\n",
    "df.time_usec = df.sort_values(df['time_usec'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df['truth_val'] = df.url.str[0:3] =='chr'\n",
    "    #for row in range(0,len(df)):\n",
    "    #a = df.truth_val.iloc[row]\n",
    "\n",
    "#code that was giving me truth value of array is ambiguous\n",
    "df['urls'] = np.where(df.url.str[0:3] =='chr', [df.url.str[71:], df.url ])\n",
    "\n",
    "def url_shortener(df):\n",
    "    if(df.url.str[0:3] =='chr'):\n",
    "        df['urls']= df.url.str[71:]\n",
    "    else:\n",
    "        df['urls']= df.url\n",
    "        \n",
    "df\n",
    "\n",
    "def url_shortener():\n",
    "    for item in df['truth_val']:\n",
    "        if ((df.truth_val.loc[item]) == true):\n",
    "            df.urls.loc[item] == df.url[72:]\n",
    "        else:\n",
    "            df.urls.loc[item] == df.url\n",
    "url_shortener()\n",
    "\n",
    "if (df['truth val'].values):\n",
    "    df['Short'] = df.url\n",
    "else:\n",
    "    df['Short'] = df.url.str[71:]\n",
    "df['Short']\n",
    "\n",
    "a = df['url']\n",
    "#select the current cell at row i in column 'url'\n",
    "long_url = a.iloc[i]\n",
    "#test if the first 3 letters of the string in the current cell are 'chr'\n",
    "if (df['url]'[0:2]=='chr'):\n",
    "    #create a new column with the shortened url's\n",
    "    df['new_url'] = long_url[71:]\n",
    "\n",
    "df\n",
    "       \n",
    "       for i in range(len(df)):\n",
    "    #if the first three letters of the url section is chr, trim the chrome extension characters\n",
    "    if((df.loc[i, 'url'][:2])=='chr'):\n",
    "        long_url = df.loc[i, 'url']\n",
    "        #create a new column with the shortened url's\n",
    "        df.iloc[i]['new_url'] = long_url[71:]\n",
    "\n",
    "df['new_url']\n",
    "for row in range(len(df)):\n",
    "    if(df.truth_val.iloc[row]):\n",
    "        df['urls'].iloc[row] = df.url.str[72:]\n",
    "    #else:\n",
    "     #   df.urls.iloc[row] = df.url\n",
    "        \n",
    "df\n",
    "\n",
    "#def url_shortenerv(x)= \n",
    " #   df['urls'] = np.vectorize(x)\n",
    "\n",
    "#check if first 3 letters of the cell at a given row under 'url' column are chr\n",
    "#if ((df.url.str[0:3].item =='chr')):\n",
    "    #create new column and add the shortened url to it\n",
    "    #df['Short Url'] = df.url.str[72:]\n",
    "#else:\n",
    "    #add the regular url to the short url column\n",
    "    #df['Short Url'] = df.url\n",
    "    \n",
    "#df['Short Url']\n",
    "\n",
    "\n",
    "#print(df.url.loc[0][71:])\n",
    "#print(df.url.iloc[1][71:])\n",
    "print(df['url'][0:4])\n",
    "    \n",
    "print(df.url.loc[0:2].str[0:3])\n",
    "print(str(df.url.str[0:3]))\n",
    "       \n",
    "def date_time(df):\n",
    "    return datetime.datetime.fromtimestamp(\n",
    "        int(df['d time'])\n",
    "    ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df['date_time'] = df.apply(date_time, axis=1)\n",
    "df\n",
    "\n",
    "def usec_to_sec(df):\n",
    "    return df['time_usec']/1000000\n",
    "        \n",
    "df['d time'] = df.apply(usec_to_sec, axis=1)\n",
    "#df['date time'] = df.apply(pd.to_datetime(df['d time']), axis=1, errors='ignore')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.iloc[i]['Date Time'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(df.iloc[i]['time_usec']))\n",
    "print(df['Date Time'].head())\n",
    "df['unixTimeStamp'] = df['time_usec'] - 210866760000000000\n",
    "df\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ts = df.iloc[i]['time_usec']\n",
    "    dt = time.localtime(ts)  # for local time\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = df['url']\n",
    "b = a.iloc[4]\n",
    "c = b[0:2]\n",
    "c\n",
    "\"\"\"\n",
    "%%timeit\n",
    "df['truth_val'] = df.url.str[0:3] =='chr'\n",
    "#df['urls'] = \"\"\n",
    "for row in range(0,len(df)):\n",
    "    a = df.truth_val.iloc[row]\n",
    "    if (a==True):\n",
    "        df['urls'].iloc[row]= df.url.loc[row, 71:]\n",
    "    else:\n",
    "        df['urls'].iloc[row]= df.url.iloc[row]\n",
    "    \n",
    "df.head()\n",
    "    \n",
    "#df['urls'].iloc[3] = df.url.str[72:]\n",
    "#df['urls'].axes\n",
    "#print(type(df['truth_val']))\n",
    "\n",
    "\n",
    "%timeit\n",
    "def url_shortener(df):\n",
    "    df['truth_val'] = df.url.str[0:3] =='chr'\n",
    "    #for row in range(0,len(df)):\n",
    "    a = df.truth_val.iloc[row]\n",
    "    if (a==True):\n",
    "        df['urls'].iloc[row]= df.url.loc[row, 71:]\n",
    "    else:\n",
    "        df['urls'].iloc[row]= df.url.iloc[row]\n",
    "\n",
    "df.head()\n",
    "\"\"\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
